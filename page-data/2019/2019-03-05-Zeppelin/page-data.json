{"componentChunkName":"component---src-templates-blog-post-js","path":"/2019/2019-03-05-Zeppelin/","result":{"data":{"site":{"siteMetadata":{"title":"Mason blog","author":"mason ko","siteUrl":"https://mason-ko.github.io","comment":{"disqusShortName":"","utterances":""},"sponsor":{"buyMeACoffeeId":"jbee"}}},"markdownRemark":{"id":"02b12c25-5ade-5814-9916-8be35c59a68b","excerpt":"Docker Compose File docker-compose.yaml Info spark가 로컬이 아닐 경우에는 spark-submit을 통해 사용하기 때문에 spark가 zeppelin 내부에 설치가 되어 있어야 함   up -d 이후   Docker Container안에서 Spark를 Download( wget http://apache.mirror.cdnetworks.com/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz )   Interpreters…","html":"<h2 id=\"docker-compose-file\" style=\"position:relative;\"><a href=\"#docker-compose-file\" aria-label=\"docker compose file permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Docker Compose File</h2>\n<p>docker-compose.yaml</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">version: \"3.0\"\nservices:\n  zeppelin1:\n    image: apache/zeppelin:0.8.0\n    container_name: docker_zeppelin_1\n    ports:\n      - \"8080:8080\"</code></pre></div>\n<h2 id=\"info\" style=\"position:relative;\"><a href=\"#info\" aria-label=\"info permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Info</h2>\n<p>spark가 로컬이 아닐 경우에는 spark-submit을 통해 사용하기 때문에<br>\nspark가 zeppelin 내부에 설치가 되어 있어야 함  </p>\n<p>up -d 이후  </p>\n<p>Docker Container안에서 Spark를 Download( wget <a href=\"http://apache.mirror.cdnetworks.com/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz\">http://apache.mirror.cdnetworks.com/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz</a> )  </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">docker exec -it docker_zepplein_1 bash\nwget http://apache.mirror.cdnetworks.com/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz\ntar -xvf spark-2.3.2-bin-hadoop2.7.tgz\nmv spark-2.3.2-bin-hadoop2.7 /spark</code></pre></div>\n<p>Interpreters에서 Create<br>\nInterpreter group 을 Spark로 설정\nProperties에 Spark 관련 Property를 추가  </p>\n<ol>\n<li>SPARK_HOME: /spark  </li>\n<li>SPARK<em>SUBMIT</em>OPTIONS: —packages datastax:spark-cassandra-connector:2.4.0-s_2.11 —conf spark.cassandra.connection.host=192.168.56.101  </li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">SPARK_HOME: /spark</code></pre></div>","frontmatter":{"title":"Zeppelin Docker Compose Yaml","date":"March 05, 2019"}}},"pageContext":{"slug":"/2019/2019-03-05-Zeppelin/","previous":{"fields":{"slug":"/2019/2019-02-15-Kafka-Cluster/"},"frontmatter":{"title":"Kafka Cluster Docker Compose Yaml"}},"next":{"fields":{"slug":"/2019/2019-03-05-Spark-Cluster/"},"frontmatter":{"title":"Spark Cluster Docker Compose Yaml"}}}},"staticQueryHashes":["2486386679","3128451518"]}