---
layout: post
title:  "Zeppelin Docker Compose Yaml"
date:   2019-03-05 14:00:00 +0900
category: 'zeppelin'
draft: false
---

## Docker Compose File

docker-compose.yaml

```
version: "3.0"
services:
  zeppelin1:
    image: apache/zeppelin:0.8.0
    container_name: docker_zeppelin_1
    ports:
      - "8080:8080"
```

## Info

spark가 로컬이 아닐 경우에는 spark-submit을 통해 사용하기 때문에  
spark가 zeppelin 내부에 설치가 되어 있어야 함  

up -d 이후  

Docker Container안에서 Spark를 Download( wget http://apache.mirror.cdnetworks.com/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz )  

```
docker exec -it docker_zepplein_1 bash
wget http://apache.mirror.cdnetworks.com/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz
tar -xvf spark-2.3.2-bin-hadoop2.7.tgz
mv spark-2.3.2-bin-hadoop2.7 /spark
```

Interpreters에서 Create  
Interpreter group 을 Spark로 설정
Properties에 Spark 관련 Property를 추가  
1. SPARK_HOME: /spark  
2. SPARK_SUBMIT_OPTIONS: --packages datastax:spark-cassandra-connector:2.4.0-s_2.11 --conf spark.cassandra.connection.host=192.168.56.101  

```

SPARK_HOME: /spark
```